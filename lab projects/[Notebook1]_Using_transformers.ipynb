{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rwJ_3xvvdWd"
      },
      "source": [
        "# Using transformers\n",
        "We will start by learning how to use transformer models for different tasks, by using the Hugging Face ``transformers`` library. Before starting, make sure you have the ``transformers`` library installed, and import it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLlgCJq4tHlz"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbzG7DyQtx8V"
      },
      "source": [
        "## Sentiment analysis\n",
        "The easiest way to use a transformer model from the Hugging Face library is by using the ``pipeline()`` function. Hugging Face describes the ``pipeline()`` function as\n",
        "> connencting a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer.\n",
        "\n",
        "For example, if we want to use a pre-trained classifier for sentiment analysis, we may do the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohw7N4fotmAF"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "sentence = \"I loved the theater yesterday\"\n",
        "classifier(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlZVLBmpw0ol"
      },
      "source": [
        "**Question.** What model is being used by default ?\n",
        "\n",
        "**Exercise.** The ``classifier`` model can process several input sentences at a time. Create a list of 3 sentences and input the whole list in order to classify the 3 sentences simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1McHnPbDuSo1"
      },
      "outputs": [],
      "source": [
        "# TODO: create a list of 3 sentences\n",
        "\n",
        "# TODO: classify the above sentences using the classifier model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBtlFSYAxpi1"
      },
      "source": [
        "**Question.** When classifying the above sentences, how sure is the model ?\n",
        "\n",
        "**Exercise.** Try and write down a sentence so that the model classifies it as being positive/negative with probabilites close to 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyP4gKhNvDDV"
      },
      "outputs": [],
      "source": [
        "# TODO: get a score as close to 0.5 as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XN29321yHac"
      },
      "source": [
        "**Discussion.** Take a pause to discuss with your classmates and with the teacher:\n",
        "- Did anyone manage to get a score close to 0.5?\n",
        "- Which sentences work best?\n",
        "- Some sentences *feel* like they should get a score close to 0.5, but they don't. Why does this happen?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTPNzd3tyqO1"
      },
      "source": [
        "## Translation\n",
        "Next we will use the ``pipeline()`` function for the task of machine translation. We will choose to load the *T5 transformer* model, provided by Google, which supports English, French, German and Romanian. In order to do that, we will specify to the ``pipeline()`` function that that we want to use the model ``google-t5/t5-base``, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aD0QiayyGA-"
      },
      "outputs": [],
      "source": [
        "translator = pipeline(\"translation\", model=\"google-t5/t5-base\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rfP2m8R3Py2"
      },
      "source": [
        "**Exercise.** Use the translator model to translate the sentence *The farmers take the cows up to the mountains during summer*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-9uMbcJ192_"
      },
      "outputs": [],
      "source": [
        "# TODO: Translate the given sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDazEsJ53rBd"
      },
      "source": [
        "**Question.** What language did the model translate the sentence to?\n",
        "\n",
        "**Exercise.** Choose a different language and have the model translate the same sentence to the new language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1J_upsK3lQ1"
      },
      "outputs": [],
      "source": [
        "# TODO: Translate the same sentece to a different language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCw3DBwU4J-2"
      },
      "source": [
        "**Exercise.** Try and translate the same sentece to Spanish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfwVd8BQ3_f2"
      },
      "outputs": [],
      "source": [
        "# TODO: try and translate to Spanish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OkvVCAQ4XJG"
      },
      "source": [
        "**Exercise.** Check the [Hugging Face Model Hub](https://huggingface.co/models) for a translation model that can translate from English to Spanish and use it to translate the sentence above.\n",
        "\n",
        "**Hint.** Use the tags in the left-hand of the Hugging Face Model Hub side in order to filter the models according to the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7hCqCQS4HNA"
      },
      "outputs": [],
      "source": [
        "# TODO: repeat the steps above with a model that handles English 2 Spanish translation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling with temperature and top-p\n",
        "We now check that our `translator` model always seems to produce the same answer for a given prompt. To that end, we create a batch of 10 identical sequences and check that the answers are always the same."
      ],
      "metadata": {
        "id": "sWhPViJHUZSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a batch with 10 identical sequences containig the word Doctor\n",
        "batch = [\"French: Doctor\"] * 10\n",
        "print(translator(batch))"
      ],
      "metadata": {
        "id": "yapM7eTZQ1zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise.** Add the options `do_sample=True`, as well as a `temperature` and a `top_p` value to the `translator` call. Are the answers any different? What `temperature` parameters give interesting answers and which don't? Do not hesitate to compare with your classmates' results."
      ],
      "metadata": {
        "id": "nhIyq8D_VTnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Generate answers with different temperature and top-p values."
      ],
      "metadata": {
        "id": "fx3KEEL9Rjn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbC0SLabRqyC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}